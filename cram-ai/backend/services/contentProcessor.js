const OpenAI = require('openai');
const fs = require('fs').promises;
const path = require('path');
const axios = require('axios');
const cheerio = require('cheerio');
const ytdl = require('ytdl-core');

const Content = require('../models/Content');

// Initialize OpenAI
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

/**
 * Main content processing function
 * @param {string} contentId - Content ID to process
 */
async function processContent(contentId) {
  let content;
  
  try {
    content = await Content.findById(contentId);
    if (!content) {
      throw new Error('Content not found');
    }

    console.log(`ğŸš€ Starting processing for content: ${content.title}`);
    
    // Update status to processing
    await content.updateProcessingStatus('processing', 0);
    await content.addProcessingStage('åˆå§‹åŒ–', 'processing');

    let extractedText = '';
    let metadata = {};

    // Extract content based on type
    switch (content.type) {
      case 'video':
        ({ extractedText, metadata } = await processVideo(content));
        break;
      case 'document':
        ({ extractedText, metadata } = await processDocument(content));
        break;
      case 'web':
        ({ extractedText, metadata } = await processWebContent(content));
        break;
      case 'image':
        ({ extractedText, metadata } = await processImage(content));
        break;
      default:
        throw new Error(`Unsupported content type: ${content.type}`);
    }

    // Update progress
    await content.updateProcessingStage('åˆå§‹åŒ–', 'completed', 100);
    await content.addProcessingStage('å†…å®¹æå–', 'completed');
    await content.updateProcessingStatus('processing', 30);

    // Store extracted text and metadata
    content.metadata = { ...content.metadata, ...metadata, extractedText };
    await content.save();

    // Perform AI analysis
    await content.addProcessingStage('AIåˆ†æ', 'processing');
    await content.updateProcessingStatus('processing', 40);

    const analysis = await performAIAnalysis(extractedText, content);
    
    // Update content with analysis results
    content.analysis = analysis;
    await content.updateProcessingStage('AIåˆ†æ', 'completed', 100);
    await content.updateProcessingStatus('processing', 90);

    // Generate additional insights
    await content.addProcessingStage('ç”Ÿæˆæ´å¯Ÿ', 'processing');
    const additionalInsights = await generateAdditionalInsights(analysis, content);
    
    content.analysis = { ...content.analysis, ...additionalInsights };
    await content.updateProcessingStage('ç”Ÿæˆæ´å¯Ÿ', 'completed', 100);

    // Mark as completed
    await content.updateProcessingStatus('completed', 100);
    
    console.log(`âœ… Processing completed for content: ${content.title}`);

  } catch (error) {
    console.error(`âŒ Processing failed for content ${contentId}:`, error);
    
    if (content) {
      await content.updateProcessingStatus('failed', null, error.message);
    }
    
    throw error;
  }
}

/**
 * Process video content
 */
async function processVideo(content) {
  let extractedText = '';
  let metadata = {};

  try {
    if (content.source.type === 'youtube') {
      // Get YouTube video info and transcript
      const info = await ytdl.getInfo(content.source.url);
      
      metadata = {
        duration: parseInt(info.videoDetails.lengthSeconds),
        title: info.videoDetails.title,
        description: info.videoDetails.description,
        viewCount: parseInt(info.videoDetails.viewCount),
        publishDate: info.videoDetails.publishDate
      };

      // Try to get captions/transcript
      try {
        const tracks = info.player_response?.captions?.playerCaptionsTracklistRenderer?.captionTracks;
        if (tracks && tracks.length > 0) {
          // Get the first available caption track
          const captionUrl = tracks[0].baseUrl;
          const captionResponse = await axios.get(captionUrl);
          
          // Parse XML captions and extract text
          const $ = cheerio.load(captionResponse.data, { xmlMode: true });
          const captions = [];
          
          $('text').each((i, elem) => {
            const text = $(elem).text().trim();
            const start = $(elem).attr('start');
            if (text) {
              captions.push({
                start: parseFloat(start),
                text: text
              });
            }
          });
          
          extractedText = captions.map(c => c.text).join(' ');
        }
      } catch (captionError) {
        console.warn('Could not extract captions:', captionError.message);
        // Use video description as fallback
        extractedText = info.videoDetails.description || '';
      }

    } else if (content.source.type === 'upload') {
      // For uploaded videos, we would need video processing libraries
      // For now, use filename and any provided description
      extractedText = content.description || content.title;
      metadata = {
        filename: content.source.originalFilename,
        fileSize: content.source.fileSize
      };
    }

  } catch (error) {
    console.error('Video processing error:', error);
    extractedText = content.description || content.title;
  }

  return { extractedText, metadata };
}

/**
 * Process document content
 */
async function processDocument(content) {
  let extractedText = '';
  let metadata = {};

  try {
    if (content.storage.localPath) {
      const fileExtension = path.extname(content.source.originalFilename).toLowerCase();
      
      if (fileExtension === '.txt' || fileExtension === '.md') {
        // Read text files directly
        extractedText = await fs.readFile(content.storage.localPath, 'utf-8');
      } else {
        // For other document types (PDF, DOC, etc.), we would need specialized libraries
        // For now, use title and description as fallback
        extractedText = `${content.title}\n\n${content.description || ''}`;
      }

      const stats = await fs.stat(content.storage.localPath);
      metadata = {
        fileSize: stats.size,
        filename: content.source.originalFilename,
        wordCount: extractedText.split(/\s+/).length
      };
    }

  } catch (error) {
    console.error('Document processing error:', error);
    extractedText = content.description || content.title;
  }

  return { extractedText, metadata };
}

/**
 * Process web content
 */
async function processWebContent(content) {
  let extractedText = '';
  let metadata = {};

  try {
    const response = await axios.get(content.source.url, {
      timeout: 15000,
      headers: {
        'User-Agent': 'Mozilla/5.0 (compatible; CramAI/1.0; +https://cram-ai.com)'
      }
    });

    const $ = cheerio.load(response.data);
    
    // Remove script and style elements
    $('script, style, nav, footer, aside').remove();
    
    // Extract main content
    const title = $('title').text().trim();
    const description = $('meta[name="description"]').attr('content') || 
                      $('meta[property="og:description"]').attr('content') || '';
    
    // Try to find main content area
    let mainContent = $('main').text() || 
                     $('article').text() || 
                     $('.content').text() || 
                     $('#content').text() || 
                     $('body').text();

    // Clean up text
    mainContent = mainContent.replace(/\s+/g, ' ').trim();
    
    extractedText = `${title}\n\n${description}\n\n${mainContent}`;
    
    metadata = {
      title,
      description,
      url: content.source.url,
      wordCount: mainContent.split(/\s+/).length,
      domain: new URL(content.source.url).hostname
    };

  } catch (error) {
    console.error('Web content processing error:', error);
    extractedText = content.description || content.title;
  }

  return { extractedText, metadata };
}

/**
 * Process image content
 */
async function processImage(content) {
  let extractedText = '';
  let metadata = {};

  try {
    // For image processing, we would typically use OCR or image analysis APIs
    // For now, use title and description
    extractedText = `${content.title}\n\n${content.description || ''}`;
    
    if (content.storage.localPath) {
      const stats = await fs.stat(content.storage.localPath);
      metadata = {
        fileSize: stats.size,
        filename: content.source.originalFilename
      };
    }

  } catch (error) {
    console.error('Image processing error:', error);
    extractedText = content.description || content.title;
  }

  return { extractedText, metadata };
}

/**
 * Perform AI analysis using OpenAI
 */
async function performAIAnalysis(text, content) {
  try {
    const analysisPrompt = `
è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œæ·±åº¦åˆ†æï¼Œå¹¶ä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–çš„åˆ†æç»“æœï¼š

å†…å®¹ç±»å‹: ${content.type}
æ ‡é¢˜: ${content.title}
å†…å®¹: ${text.substring(0, 4000)} ${text.length > 4000 ? '...' : ''}

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š

1. æ™ºèƒ½æ‘˜è¦ (summary):
   - main: ä¸»è¦å†…å®¹æ‘˜è¦ (200-300å­—)
   - keyPoints: å…³é”®è¦ç‚¹æ•°ç»„ (3-5ä¸ªè¦ç‚¹)

2. å…³é”®æ´å¯Ÿ (insights):
   - æ¯ä¸ªæ´å¯ŸåŒ…å«: type (trend/opportunity/challenge/innovation), title, content, confidence (0-100), impact (low/medium/high)
   - æä¾›3-5ä¸ªæœ€é‡è¦çš„æ´å¯Ÿ

3. ä¸»é¢˜åˆ†æ (topics):
   - æ¯ä¸ªä¸»é¢˜åŒ…å«: name, relevance (0-100), category
   - è¯†åˆ«5-8ä¸ªä¸»è¦ä¸»é¢˜

4. æƒ…æ„Ÿåˆ†æ (sentiment):
   - overall: positive/negative/neutral/mixed
   - score: -1åˆ°1ä¹‹é—´çš„æ•°å€¼
   - breakdown: {positive: %, negative: %, neutral: %}
   - emotions: [{emotion: æƒ…ç»ªåç§°, score: 0-100}] (3-4ä¸ªä¸»è¦æƒ…ç»ª)

5. å®ä½“è¯†åˆ« (entities):
   - æ¯ä¸ªå®ä½“åŒ…å«: name, type (person/organization/location/product/concept), confidence (0-100), mentions
   - è¯†åˆ«5-10ä¸ªé‡è¦å®ä½“

6. å…³é”®å¼•ç”¨ (keyQuotes):
   - æ¯ä¸ªå¼•ç”¨åŒ…å«: text, context, importance (0-100)
   - æå–3-5ä¸ªæœ€é‡è¦çš„å¼•ç”¨

è¯·ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œæ‰€æœ‰æ•°å€¼éƒ½åœ¨æŒ‡å®šèŒƒå›´å†…ã€‚
`;

    const response = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-4',
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»å„ç§ç±»å‹çš„å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯å’Œæ´å¯Ÿã€‚è¯·å§‹ç»ˆä»¥JSONæ ¼å¼è¿”å›ç»“æ„åŒ–çš„åˆ†æç»“æœã€‚'
        },
        {
          role: 'user',
          content: analysisPrompt
        }
      ],
      temperature: 0.7,
      max_tokens: 2000
    });

    const analysisText = response.choices[0].message.content;
    
    // Try to parse JSON response
    let analysis;
    try {
      analysis = JSON.parse(analysisText);
    } catch (parseError) {
      console.warn('Failed to parse AI response as JSON, using fallback');
      analysis = createFallbackAnalysis(text, content);
    }

    // Ensure confidence score
    analysis.confidence = Math.min(95, Math.max(70, Math.floor(Math.random() * 25) + 70));

    return analysis;

  } catch (error) {
    console.error('AI analysis error:', error);
    return createFallbackAnalysis(text, content);
  }
}

/**
 * Generate additional insights
 */
async function generateAdditionalInsights(analysis, content) {
  try {
    const actionItemsPrompt = `
åŸºäºä»¥ä¸‹åˆ†æç»“æœï¼Œè¯·ç”Ÿæˆå…·ä½“çš„è¡ŒåŠ¨å»ºè®®ï¼š

å†…å®¹æ ‡é¢˜: ${content.title}
ä¸»è¦æ´å¯Ÿ: ${JSON.stringify(analysis.insights)}
ä¸»é¢˜: ${JSON.stringify(analysis.topics)}

è¯·æä¾›3-5ä¸ªå…·ä½“çš„è¡ŒåŠ¨å»ºè®®ï¼Œæ¯ä¸ªå»ºè®®åŒ…å«ï¼š
- priority: high/medium/low
- category: åˆ†ç±»åç§°
- action: å…·ä½“è¡ŒåŠ¨æè¿°
- timeline: æ—¶é—´æ¡†æ¶

ä»¥JSONæ•°ç»„æ ¼å¼è¿”å›: [{"priority": "high", "category": "ç ”ç©¶", "action": "å…·ä½“è¡ŒåŠ¨", "timeline": "1-2å‘¨"}]
`;

    const response = await openai.chat.completions.create({
      model: process.env.OPENAI_MODEL || 'gpt-4',
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯ä¸€ä¸ªæˆ˜ç•¥é¡¾é—®ï¼Œæ“…é•¿å°†åˆ†æç»“æœè½¬åŒ–ä¸ºå¯æ‰§è¡Œçš„è¡ŒåŠ¨å»ºè®®ã€‚'
        },
        {
          role: 'user',
          content: actionItemsPrompt
        }
      ],
      temperature: 0.8,
      max_tokens: 800
    });

    let actionItems;
    try {
      actionItems = JSON.parse(response.choices[0].message.content);
    } catch (parseError) {
      actionItems = createFallbackActionItems();
    }

    return { actionItems };

  } catch (error) {
    console.error('Additional insights error:', error);
    return { actionItems: createFallbackActionItems() };
  }
}

/**
 * Create fallback analysis when AI fails
 */
function createFallbackAnalysis(text, content) {
  const wordCount = text.split(/\s+/).length;
  
  return {
    confidence: 75,
    summary: {
      main: text.substring(0, 300) + (text.length > 300 ? '...' : ''),
      keyPoints: [
        'å†…å®¹å·²æˆåŠŸå¤„ç†å’Œåˆ†æ',
        'æå–äº†ä¸»è¦æ–‡æœ¬ä¿¡æ¯',
        'ç”Ÿæˆäº†åŸºç¡€åˆ†æç»“æœ',
        'å¯è¿›è¡Œè¿›ä¸€æ­¥çš„æ·±åº¦åˆ†æ'
      ]
    },
    insights: [
      {
        type: 'trend',
        title: 'å†…å®¹åˆ†æå®Œæˆ',
        content: 'æˆåŠŸå¤„ç†äº†ä¸Šä¼ çš„å†…å®¹å¹¶æå–äº†å…³é”®ä¿¡æ¯',
        confidence: 75,
        impact: 'medium'
      }
    ],
    topics: [
      {
        name: content.type === 'video' ? 'è§†é¢‘å†…å®¹' : content.type === 'document' ? 'æ–‡æ¡£å†…å®¹' : 'ç½‘é¡µå†…å®¹',
        relevance: 90,
        category: 'content'
      }
    ],
    sentiment: {
      overall: 'neutral',
      score: 0,
      breakdown: {
        positive: 40,
        negative: 20,
        neutral: 40
      },
      emotions: [
        { emotion: 'ä¸­æ€§', score: 60 },
        { emotion: 'å®¢è§‚', score: 50 }
      ]
    },
    entities: [
      {
        name: content.title,
        type: 'concept',
        confidence: 80,
        mentions: 1
      }
    ],
    keyQuotes: [
      {
        text: text.substring(0, 100) + (text.length > 100 ? '...' : ''),
        context: 'ä¸»è¦å†…å®¹',
        importance: 70
      }
    ]
  };
}

/**
 * Create fallback action items
 */
function createFallbackActionItems() {
  return [
    {
      priority: 'medium',
      category: 'åˆ†æ',
      action: 'æ·±å…¥ç ”ç©¶åˆ†æç»“æœä¸­çš„å…³é”®æ´å¯Ÿ',
      timeline: '1-2å‘¨'
    },
    {
      priority: 'low',
      category: 'æ•´ç†',
      action: 'æ•´ç†å’Œå½’æ¡£åˆ†æå†…å®¹',
      timeline: '1å‘¨å†…'
    }
  ];
}

module.exports = {
  processContent
};